
seed: 42

datasets:
  ViNLI-Zalo-supervised:
    data_path: "./data/segment/ViNLI-Zalo-supervised.json"
    train_path: "./data/train_test_split/ViNLI-Zalo-supervised-segment-train.json"
    test_path: "./data/train_test_split/ViNLI-Zalo-supervised-segment-test.json"
    data_module: "ViNLIZaloRegressionDataset"
    test_size: 0.3
    reverse_input: false
    force_remake: false
    
  ViNLI-SimCSE-supervised:
    data_path: "./data/segment/ViNLI-Zalo-supervised.json"
    train_path: "./data/train_test_split/ViNLI-SimCSE-supervised-segment-train.json"
    test_path: "./data/train_test_split/ViNLI-SimCSE-supervised-segment-test.json"
    data_module: "ViNLIZaloDataset"
    test_size: 0.3
    reverse_input: true
    force_remake: false

  IR:
    data_path: "./data/segment/train-IR.json"
    train_path: "./data/train_test_split/train-IR-segment-train.json"
    test_path: "./data/train_test_split/train-IR-segment-test.json"
    data_module: "IRSegmentDataset"
    test_size: 0.3
    reverse_input: false
    force_remake: false

  ViMMRC:
    data_path: "./data/segment/ViMMRC.json"
    train_path: "./data/train_test_split/ViMMRC-segment-train.json"
    test_path: "./data/train_test_split/ViMMRC-segment-test.json"
    data_module: "ViMMRCSegmentDataset"
    test_size: 0.3
    reverse_input: false
    force_remake: false

  UIT-ViQuAD:
    data_path: "./data/segment/UIT-ViQuAD.json"
    train_path: "./data/train_test_split/UIT-ViQuAD-segment-train.json"
    test_path: "./data/train_test_split/UIT-ViQuAD-segment-test.json"
    data_module: "ViMMRCSegmentDataset"
    test_size: 0.3
    reverse_input: false
    force_remake: false

  SQuAD-Vi:
    data_path: "./data/segment/SQuAD-Vi.json"
    train_path: "./data/train_test_split/SQuAD-Vi-segment-train.json"
    test_path: "./data/train_test_split/SQuAD-Vi-segment-test.json"
    data_module: "ViMMRCSegmentDataset"
    test_size: 0.3
    reverse_input: false
    force_remake: false

tokenizer: "vinai/phobert-base-v2"
hf_cache: "../hf_cache"
max_length: 515

pretrained_path: null
load_state_dict_option: 'all_matched_keys'
model:
  model_type: "Roberta"
  hidden_size: 768
  num_hidden_layers: 12
  num_attention_heads: 12
  intermediate_size: 3072
  hidden_act: "gelu"
  hidden_dropout_prob: 0.1
  attention_probs_dropout_prob: 0.1
  max_position_embeddings: 515
  position_embedding_type: "absolute"
  torch_dtype: "float32"
  type_vocab_size: 1
  layer_norm_eps: 0.00001
  initializer_range: 0.02
  pooler_fc_size: 768
  pooler_num_attention_heads: 12
  pooler_num_fc_layers: 3
  pooler_size_per_head: 128
  pooler_type: "first_token_transform"
  classifier_dropout: null
  tokenizer_class: 'PhobertTokenizer'
  num_labels: 2
  id2label:
    0: NEG
    1: POS
  use_cache: true
  problem_type: null

do_train: true
max_epochs: 100
batch_size: 8

input_fields:
- input_ids
- attention_mask
# - token_type_ids
- position_ids
- labels

shuffle_train: true
shuffle_test: false
num_workers: 1
device: 0
optimizer: "AdamW"
lr: 0.00005
model_checkpoints: "./model_checkpoints/roberta-base-classifier/"
train_from_last_epoch: true

