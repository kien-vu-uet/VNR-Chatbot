{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/workspace/nlplab/kienvt/KLTN/kenv/lib/python3.8/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from components import *\n",
    "import argparse\n",
    "import yaml\n",
    "import torch\n",
    "import os\n",
    "import re\n",
    "import time\n",
    "from transformers import AutoTokenizer\n",
    "# from tqdm import tqdm\n",
    "# from torch.nn.parallel import DistributedDataParallel, DataParallel\n",
    "from torch.utils.data import ConcatDataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ['CUDA_LAUNCH_BLOCKING'] = '1'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "config_path = './config/ViNLI-Zalo.yml'\n",
    "with open(config_path, 'r') as f:\n",
    "    opt = yaml.safe_load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'seed': 42,\n",
       " 'datasets': {'ViNLI-Zalo': {'data_name': 'ViNLI-Zalo-supervised',\n",
       "   'data_path': './data/segment/ViNLI-Zalo-supervised.json',\n",
       "   'train_path': './data/train_test_split/ViNLI-Zalo-supervised-train.json',\n",
       "   'test_path': './data/train_test_split/ViNLI-Zalo-supervised-test.json',\n",
       "   'data_module': 'ViNLIZaloDataset',\n",
       "   'test_size': 0.1}},\n",
       " 'tokenizer': 'vinai/phobert-base-v2',\n",
       " 'hf_cache': '../hf_cache',\n",
       " 'max_length': 515,\n",
       " 'pretrained_path': None,\n",
       " 'load_state_dict_option': 'encoder_only',\n",
       " 'model': {'model_type': 'Roberta',\n",
       "  'hidden_size': 768,\n",
       "  'num_hidden_layers': 12,\n",
       "  'num_attention_heads': 12,\n",
       "  'intermediate_size': 3072,\n",
       "  'hidden_act': 'gelu',\n",
       "  'hidden_dropout_prob': 0.1,\n",
       "  'attention_probs_dropout_prob': 0.1,\n",
       "  'max_position_embeddings': 515,\n",
       "  'position_embedding_type': 'absolute',\n",
       "  'type_vocab_size': 2,\n",
       "  'layer_norm_eps': 1e-05,\n",
       "  'initializer_range': 0.02,\n",
       "  'classifier_dropout': 0.1,\n",
       "  'num_labels': 2,\n",
       "  'problem_type': 'single_label_classification'},\n",
       " 'max_epochs': 300,\n",
       " 'batch_size': 4,\n",
       " 'shuffle_train': True,\n",
       " 'shuffle_test': False,\n",
       " 'device': 'cuda',\n",
       " 'optimizer': 'Adam',\n",
       " 'lr': 0.0005,\n",
       " 'model_checkpoints': './model_checkpoints/ViNLI-Zalo/',\n",
       " 'train_from_last_epoch': True}"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "opt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "opt['tokenizer'] = AutoTokenizer.from_pretrained(opt['tokenizer'], cache_dir=opt['hf_cache'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Num of training samples: 11873\n",
      "Num of testing samples: 1319\n"
     ]
    }
   ],
   "source": [
    "total_train_set, total_test_set = [], []\n",
    "for k, v in opt['datasets'].items():\n",
    "    train_set, test_set = get_dataset(**v, **opt)\n",
    "    total_train_set.append(train_set)\n",
    "    total_test_set.append(test_set)\n",
    "total_train_set = ConcatDataset(total_train_set)\n",
    "total_test_set = ConcatDataset(total_test_set)\n",
    "print('Num of training samples:', len(total_train_set))\n",
    "print('Num of testing samples:', len(total_test_set))\n",
    "train_loader = get_dataloader(total_train_set, 'train', **opt)\n",
    "test_loader = get_dataloader(total_test_set, 'test', **opt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input_ids torch.Size([4, 515])\n",
      "attention_mask torch.Size([4, 515])\n",
      "token_type_ids torch.Size([4, 515])\n",
      "labels torch.Size([4])\n",
      "position_ids torch.Size([4, 515])\n"
     ]
    }
   ],
   "source": [
    "batch = next(iter(train_loader))\n",
    "for k, v in batch.items():\n",
    "    print(k, v.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'input_ids': tensor([[   0, 8461,   24,  ...,    1,    1,    1],\n",
       "         [   0, 8284,  741,  ...,   33,  909,    2],\n",
       "         [   0,  432,  245,  ...,    1,    1,    1],\n",
       "         [   0,  432,  426,  ...,    1,    1,    1]]),\n",
       " 'attention_mask': tensor([[1., 1., 1.,  ..., 0., 0., 0.],\n",
       "         [1., 1., 1.,  ..., 1., 1., 1.],\n",
       "         [1., 1., 1.,  ..., 0., 0., 0.],\n",
       "         [1., 1., 1.,  ..., 0., 0., 0.]]),\n",
       " 'token_type_ids': tensor([[0, 0, 0,  ..., 1, 1, 1],\n",
       "         [0, 0, 0,  ..., 1, 1, 1],\n",
       "         [0, 0, 0,  ..., 1, 1, 1],\n",
       "         [0, 0, 0,  ..., 1, 1, 1]]),\n",
       " 'labels': tensor([0, 1, 0, 0]),\n",
       " 'position_ids': tensor([[  0,   1,   2,  ..., 512, 513, 514],\n",
       "         [  0,   1,   2,  ..., 512, 513, 514],\n",
       "         [  0,   1,   2,  ..., 512, 513, 514],\n",
       "         [  0,   1,   2,  ..., 512, 513, 514]])}"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(False)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.any(batch['input_ids'] >= opt['tokenizer'].vocab_size + 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total parameters: 135197954\n"
     ]
    }
   ],
   "source": [
    "model = load_backbone(**opt)\n",
    "# print(model)\n",
    "pytorch_total_params = sum(p.numel() for p in model.parameters())\n",
    "print('Total parameters:', pytorch_total_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(opt['device'])\n",
    "model.to(device)\n",
    "\n",
    "optimizer = getattr(torch.optim, opt['optimizer'])(model.parameters(), lr=opt['lr'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5213193297386169\n"
     ]
    }
   ],
   "source": [
    "# batch['position_ids'] = torch.arange(0, opt['model']['max_position_embeddings'], dtype=torch.long).expand(opt['batch_size'], -1)\n",
    "batch = {k:v.to(device) for k,v in batch.items()}\n",
    "\n",
    "optimizer.zero_grad()\n",
    "outputs = model(**batch)\n",
    "\n",
    "loss = outputs.loss\n",
    "print(loss.item())\n",
    "loss.backward()\n",
    "optimizer.step()\n",
    "batch = {k:v.cpu() for k,v in batch.items()}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from tqdm import tqdm\n",
    "from sklearn.metrics import accuracy_score, f1_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "start_logits = torch.softmax(torch.randn((100, 2)), dim=-1)\n",
    "start_labels = torch.randint(0, 2, (100, 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.0504, 0.9496],\n",
      "        [0.6420, 0.3580],\n",
      "        [0.4658, 0.5342],\n",
      "        [0.1141, 0.8859],\n",
      "        [0.7643, 0.2357],\n",
      "        [0.2941, 0.7059],\n",
      "        [0.8811, 0.1189],\n",
      "        [0.2666, 0.7334],\n",
      "        [0.3587, 0.6413],\n",
      "        [0.6410, 0.3590],\n",
      "        [0.5825, 0.4175],\n",
      "        [0.4967, 0.5033],\n",
      "        [0.6839, 0.3161],\n",
      "        [0.6982, 0.3018],\n",
      "        [0.8474, 0.1526],\n",
      "        [0.6509, 0.3491],\n",
      "        [0.5729, 0.4271],\n",
      "        [0.6218, 0.3782],\n",
      "        [0.8771, 0.1229],\n",
      "        [0.6916, 0.3084],\n",
      "        [0.2046, 0.7954],\n",
      "        [0.1067, 0.8933],\n",
      "        [0.9328, 0.0672],\n",
      "        [0.1703, 0.8297],\n",
      "        [0.6900, 0.3100],\n",
      "        [0.5119, 0.4881],\n",
      "        [0.8172, 0.1828],\n",
      "        [0.5643, 0.4357],\n",
      "        [0.1998, 0.8002],\n",
      "        [0.1537, 0.8463],\n",
      "        [0.0659, 0.9341],\n",
      "        [0.6595, 0.3405],\n",
      "        [0.4290, 0.5710],\n",
      "        [0.4847, 0.5153],\n",
      "        [0.3896, 0.6104],\n",
      "        [0.4635, 0.5365],\n",
      "        [0.6442, 0.3558],\n",
      "        [0.2426, 0.7574],\n",
      "        [0.3021, 0.6979],\n",
      "        [0.4786, 0.5214],\n",
      "        [0.2153, 0.7847],\n",
      "        [0.8848, 0.1152],\n",
      "        [0.4699, 0.5301],\n",
      "        [0.8164, 0.1836],\n",
      "        [0.9587, 0.0413],\n",
      "        [0.9574, 0.0426],\n",
      "        [0.1339, 0.8661],\n",
      "        [0.1680, 0.8320],\n",
      "        [0.3118, 0.6882],\n",
      "        [0.8174, 0.1826],\n",
      "        [0.6694, 0.3306],\n",
      "        [0.9322, 0.0678],\n",
      "        [0.6568, 0.3432],\n",
      "        [0.4397, 0.5603],\n",
      "        [0.9240, 0.0760],\n",
      "        [0.3997, 0.6003],\n",
      "        [0.3925, 0.6075],\n",
      "        [0.8788, 0.1212],\n",
      "        [0.1730, 0.8270],\n",
      "        [0.7237, 0.2763],\n",
      "        [0.0497, 0.9503],\n",
      "        [0.8910, 0.1090],\n",
      "        [0.6345, 0.3655],\n",
      "        [0.1299, 0.8701],\n",
      "        [0.3002, 0.6998],\n",
      "        [0.8538, 0.1462],\n",
      "        [0.8258, 0.1742],\n",
      "        [0.4031, 0.5969],\n",
      "        [0.2761, 0.7239],\n",
      "        [0.6893, 0.3107],\n",
      "        [0.4701, 0.5299],\n",
      "        [0.1753, 0.8247],\n",
      "        [0.7634, 0.2366],\n",
      "        [0.9236, 0.0764],\n",
      "        [0.9281, 0.0719],\n",
      "        [0.8106, 0.1894],\n",
      "        [0.4231, 0.5769],\n",
      "        [0.8071, 0.1929],\n",
      "        [0.2801, 0.7199],\n",
      "        [0.6184, 0.3816],\n",
      "        [0.6434, 0.3566],\n",
      "        [0.4943, 0.5057],\n",
      "        [0.0790, 0.9210],\n",
      "        [0.3764, 0.6236],\n",
      "        [0.4759, 0.5241],\n",
      "        [0.2865, 0.7135],\n",
      "        [0.7823, 0.2177],\n",
      "        [0.5011, 0.4989],\n",
      "        [0.4519, 0.5481],\n",
      "        [0.7220, 0.2780],\n",
      "        [0.2440, 0.7560],\n",
      "        [0.5242, 0.4758],\n",
      "        [0.1342, 0.8658],\n",
      "        [0.8589, 0.1411],\n",
      "        [0.8142, 0.1858],\n",
      "        [0.4594, 0.5406],\n",
      "        [0.3609, 0.6391],\n",
      "        [0.7491, 0.2509],\n",
      "        [0.6958, 0.3042],\n",
      "        [0.4353, 0.5647]])\n",
      "tensor([[0],\n",
      "        [0],\n",
      "        [0],\n",
      "        [1],\n",
      "        [1],\n",
      "        [1],\n",
      "        [1],\n",
      "        [1],\n",
      "        [0],\n",
      "        [1],\n",
      "        [0],\n",
      "        [0],\n",
      "        [1],\n",
      "        [0],\n",
      "        [0],\n",
      "        [1],\n",
      "        [0],\n",
      "        [0],\n",
      "        [1],\n",
      "        [0],\n",
      "        [1],\n",
      "        [0],\n",
      "        [0],\n",
      "        [1],\n",
      "        [1],\n",
      "        [1],\n",
      "        [1],\n",
      "        [0],\n",
      "        [1],\n",
      "        [0],\n",
      "        [0],\n",
      "        [0],\n",
      "        [0],\n",
      "        [1],\n",
      "        [1],\n",
      "        [1],\n",
      "        [0],\n",
      "        [1],\n",
      "        [0],\n",
      "        [0],\n",
      "        [1],\n",
      "        [0],\n",
      "        [0],\n",
      "        [0],\n",
      "        [0],\n",
      "        [1],\n",
      "        [1],\n",
      "        [1],\n",
      "        [1],\n",
      "        [0],\n",
      "        [1],\n",
      "        [0],\n",
      "        [0],\n",
      "        [1],\n",
      "        [0],\n",
      "        [0],\n",
      "        [1],\n",
      "        [1],\n",
      "        [1],\n",
      "        [0],\n",
      "        [0],\n",
      "        [0],\n",
      "        [0],\n",
      "        [1],\n",
      "        [0],\n",
      "        [1],\n",
      "        [0],\n",
      "        [0],\n",
      "        [1],\n",
      "        [0],\n",
      "        [0],\n",
      "        [0],\n",
      "        [1],\n",
      "        [1],\n",
      "        [0],\n",
      "        [0],\n",
      "        [1],\n",
      "        [0],\n",
      "        [0],\n",
      "        [1],\n",
      "        [1],\n",
      "        [0],\n",
      "        [0],\n",
      "        [0],\n",
      "        [0],\n",
      "        [1],\n",
      "        [1],\n",
      "        [1],\n",
      "        [0],\n",
      "        [0],\n",
      "        [1],\n",
      "        [1],\n",
      "        [1],\n",
      "        [0],\n",
      "        [1],\n",
      "        [1],\n",
      "        [0],\n",
      "        [1],\n",
      "        [1],\n",
      "        [1]])\n"
     ]
    }
   ],
   "source": [
    "print(start_logits)\n",
    "print(start_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "b_logits = iter(list(torch.chunk(start_logits, chunks=10, dim=0)))\n",
    "b_labels = iter(list(torch.chunk(start_labels, chunks=10, dim=0)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([10, 2])"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "next(b_logits).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "10it [00:00, 1425.18it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([1, 0, 1, 1, 0, 1, 0, 1, 1, 0])\n",
      "tensor([0, 0, 0, 1, 1, 1, 1, 1, 0, 1])\n",
      "tensor([0, 1, 0, 0, 0, 0, 0, 0, 0, 0])\n",
      "tensor([0, 0, 1, 0, 0, 1, 0, 0, 1, 0])\n",
      "tensor([1, 1, 0, 1, 0, 0, 0, 0, 1, 1])\n",
      "tensor([1, 0, 0, 1, 1, 1, 1, 0, 1, 0])\n",
      "tensor([1, 0, 1, 1, 1, 1, 0, 1, 1, 1])\n",
      "tensor([0, 0, 0, 1, 1, 1, 0, 1, 0, 0])\n",
      "tensor([1, 0, 1, 0, 0, 0, 1, 1, 1, 0])\n",
      "tensor([1, 0, 0, 0, 0, 1, 1, 1, 1, 0])\n",
      "tensor([0, 0, 0, 1, 0, 1, 1, 0, 1, 0])\n",
      "tensor([1, 0, 0, 1, 0, 0, 1, 1, 1, 0])\n",
      "tensor([1, 0, 0, 1, 1, 0, 0, 1, 1, 0])\n",
      "tensor([0, 0, 0, 1, 0, 1, 0, 0, 1, 0])\n",
      "tensor([1, 1, 0, 0, 0, 0, 1, 0, 1, 0])\n",
      "tensor([0, 0, 1, 1, 0, 0, 1, 0, 0, 1])\n",
      "tensor([0, 1, 1, 1, 1, 1, 0, 0, 1, 0])\n",
      "tensor([1, 0, 0, 0, 0, 1, 1, 1, 0, 0])\n",
      "tensor([1, 0, 1, 0, 0, 1, 1, 0, 0, 1])\n",
      "tensor([1, 1, 1, 0, 1, 1, 0, 1, 1, 1])\n",
      "0.53 0.515463912626209\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "t_loss, tp, tn, fp, fn = 0., 0, 0, 0, 0\n",
    "\n",
    "for logits_, labels_ in tqdm(zip(b_logits, b_labels)):\n",
    "    logits = torch.argmax(logits_, dim=-1).flatten()\n",
    "    labels = labels_.flatten()\n",
    "    print(logits)\n",
    "    print(labels)\n",
    "    tp += torch.sum(((logits == 1) & (labels == 1))).item()\n",
    "    tn += torch.sum(((logits == 0) & (labels == 0))).item()\n",
    "    fp += torch.sum(((logits == 1) & (labels == 0))).item()\n",
    "    fn += torch.sum(((logits == 0) & (labels == 1))).item()\n",
    "\n",
    "acc = (tp + tn) / (tp + tn + fp + fn)\n",
    "pre = (tp + 1e-8) / (tp + fp + 1e-8)\n",
    "rec = (tp + 1e-8) / (tp + fn + 1e-8)\n",
    "f1 = (2 * pre * rec) / (pre + rec + 1e-8) \n",
    "\n",
    "print(acc, f1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.53\n",
      "0.5154639175257733\n"
     ]
    }
   ],
   "source": [
    "print(accuracy_score(start_labels.numpy(), torch.argmax(start_logits, dim=-1).numpy()))\n",
    "print(f1_score(start_labels.numpy(), torch.argmax(start_logits, dim=-1).numpy()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "10\n",
      "11\n",
      "12\n",
      "13\n",
      "14\n",
      "15\n",
      "16\n",
      "17\n",
      "18\n",
      "19\n",
      "20\n",
      "21\n",
      "22\n",
      "23\n",
      "24\n",
      "25\n",
      "26\n",
      "27\n",
      "28\n",
      "29\n",
      "30\n",
      "31\n",
      "32\n",
      "33\n",
      "34\n",
      "35\n",
      "36\n",
      "37\n",
      "38\n",
      "39\n",
      "40\n",
      "41\n",
      "42\n",
      "43\n",
      "44\n",
      "45\n",
      "46\n",
      "47\n",
      "48\n",
      "49\n",
      "50\n",
      "51\n",
      "52\n",
      "53\n",
      "54\n",
      "55\n",
      "56\n",
      "57\n",
      "58\n",
      "59\n",
      "60\n",
      "61\n",
      "62\n",
      "63\n",
      "64\n",
      "65\n",
      "66\n",
      "67\n",
      "68\n",
      "69\n",
      "70\n",
      "71\n",
      "72\n",
      "73\n",
      "74\n",
      "75\n",
      "76\n",
      "77\n",
      "78\n",
      "79\n",
      "80\n",
      "81\n",
      "82\n",
      "83\n",
      "84\n",
      "85\n",
      "86\n",
      "87\n",
      "88\n",
      "89\n",
      "90\n",
      "91\n",
      "92\n",
      "93\n",
      "94\n",
      "95\n",
      "96\n",
      "97\n",
      "98\n",
      "99\n"
     ]
    }
   ],
   "source": [
    "from tqdm import tqdm\n",
    "f = open('./training_logs.txt', 'w')\n",
    "for i in tqdm(range(100), file=f):\n",
    "    print(i)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "kenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
